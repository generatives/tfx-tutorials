{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.30.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Definition of Beam TFX runner.\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "from absl import logging\n",
    "from tfx.dsl.compiler import compiler\n",
    "from tfx.dsl.compiler import constants\n",
    "from tfx.dsl.components.base import base_component\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.orchestration import pipeline as pipeline_py\n",
    "from tfx.orchestration.local import runner_utils\n",
    "from tfx.orchestration.portable import launcher\n",
    "from tfx.orchestration.portable import runtime_parameter_utils\n",
    "from tfx.orchestration.portable import tfx_runner\n",
    "from tfx.utils import telemetry_utils\n",
    "\n",
    "\n",
    "class CustomLocalDagRunner(tfx_runner.TfxRunner):\n",
    "  \"\"\"Local TFX DAG runner using a runtime id compatible with Windows folder naming.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    \"\"\"Initializes LocalDagRunner as a TFX orchestrator.\"\"\"\n",
    "    pass\n",
    "\n",
    "  def run(self, pipeline: pipeline_py.Pipeline) -> None:\n",
    "    \"\"\"Runs given logical pipeline locally.\n",
    "    Args:\n",
    "      pipeline: Logical pipeline containing pipeline args and components.\n",
    "    \"\"\"\n",
    "    for component in pipeline.components:\n",
    "      # TODO(b/187122662): Pass through pip dependencies as a first-class\n",
    "      # component flag.\n",
    "      if isinstance(component, base_component.BaseComponent):\n",
    "        component._resolve_pip_dependencies(  # pylint: disable=protected-access\n",
    "            pipeline.pipeline_info.pipeline_root)\n",
    "\n",
    "    c = compiler.Compiler()\n",
    "    pipeline = c.compile(pipeline)\n",
    "\n",
    "    # Substitute the runtime parameter to be a concrete run_id\n",
    "    runtime_parameter_utils.substitute_runtime_parameter(\n",
    "        pipeline, {\n",
    "            constants.PIPELINE_RUN_ID_PARAMETER_NAME:\n",
    "                datetime.datetime.now().strftime('%d-%m-%YT%H.%M.%S.%f'),\n",
    "        })\n",
    "\n",
    "    deployment_config = runner_utils.extract_local_deployment_config(pipeline)\n",
    "    connection_config = deployment_config.metadata_connection_config\n",
    "\n",
    "    logging.info('Running pipeline:\\n %s', pipeline)\n",
    "    logging.info('Using deployment config:\\n %s', deployment_config)\n",
    "    logging.info('Using connection config:\\n %s', connection_config)\n",
    "\n",
    "    with telemetry_utils.scoped_labels(\n",
    "        {telemetry_utils.LABEL_TFX_RUNNER: 'local'}):\n",
    "      # Run each component. Note that the pipeline.components list is in\n",
    "      # topological order.\n",
    "      #\n",
    "      # TODO(b/171319478): After IR-based execution is used, used multi-threaded\n",
    "      # execution so that independent components can be run in parallel.\n",
    "      for node in pipeline.nodes:\n",
    "        pipeline_node = node.pipeline_node\n",
    "        node_id = pipeline_node.node_info.id\n",
    "        executor_spec = runner_utils.extract_executor_spec(\n",
    "            deployment_config, node_id)\n",
    "        custom_driver_spec = runner_utils.extract_custom_driver_spec(\n",
    "            deployment_config, node_id)\n",
    "\n",
    "        component_launcher = launcher.Launcher(\n",
    "            pipeline_node=pipeline_node,\n",
    "            mlmd_connection=metadata.Metadata(connection_config),\n",
    "            pipeline_info=pipeline.pipeline_info,\n",
    "            pipeline_runtime_spec=pipeline.runtime_spec,\n",
    "            executor_spec=executor_spec,\n",
    "            custom_driver_spec=custom_driver_spec)\n",
    "        logging.info('Component %s is running.', node_id)\n",
    "        component_launcher.launch()\n",
    "        logging.info('Component %s is finished.', node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We will create two pipelines. One for schema generation and one for training.\n",
    "SCHEMA_PIPELINE_NAME = \"penguin-tfdv-schema\"\n",
    "PIPELINE_NAME = \"penguin-tfdv\"\n",
    "\n",
    "# Output directory to store artifacts generated from the pipeline.\n",
    "SCHEMA_PIPELINE_ROOT = os.path.join('pipelines', SCHEMA_PIPELINE_NAME)\n",
    "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
    "# Path to a SQLite DB file to use as an MLMD storage.\n",
    "SCHEMA_METADATA_PATH = os.path.join('metadata', SCHEMA_PIPELINE_NAME,\n",
    "                                    'metadata.db')\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "\n",
    "# Output directory where created models from the pipeline will be exported.\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Set default logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\\\\data.csv',\n",
       " <http.client.HTTPMessage at 0x20134405490>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
    "_data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
    "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
    "urllib.request.urlretrieve(_data_url, _data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5dc08a3e4c1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                             \u001b[0mpipeline_root\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                             \u001b[0mdata_root\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                             metadata_path: str) -> tfx.dsl.Pipeline:\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[1;34m\"\"\"Creates a pipeline for schema generation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# Brings data into the pipeline.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfx' is not defined"
     ]
    }
   ],
   "source": [
    "def _create_schema_pipeline(pipeline_name: str,\n",
    "                            pipeline_root: str,\n",
    "                            data_root: str,\n",
    "                            metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a pipeline for schema generation.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # NEW: Computes statistics over data for visualization and schema generation.\n",
    "  statistics_gen = tfx.components.StatisticsGen(\n",
    "      examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # NEW: Generates schema based on the generated statistics.\n",
    "  schema_gen = tfx.components.SchemaGen(\n",
    "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "\n",
    "  components = [\n",
    "      example_gen,\n",
    "      statistics_gen,\n",
    "      schema_gen,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata.sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Running pipeline:\n",
      " pipeline_info {\n",
      "  id: \"penguin-tfdv-schema\"\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "      }\n",
      "      id: \"CsvExampleGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv-schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T14.54.58.974908\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"input_base\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"input_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_data_format\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 6\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "      }\n",
      "      id: \"StatisticsGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv-schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T14.54.58.974908\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv-schema\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T14.54.58.974908\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    downstream_nodes: \"SchemaGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "      }\n",
      "      id: \"SchemaGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv-schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T14.54.58.974908\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv-schema\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T14.54.58.974908\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"infer_feature_shape\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "runtime_spec {\n",
      "  pipeline_root {\n",
      "    field_value {\n",
      "      string_value: \"pipelines\\\\penguin-tfdv-schema\"\n",
      "    }\n",
      "  }\n",
      "  pipeline_run_id {\n",
      "    field_value {\n",
      "      string_value: \"17-06-2021T14.54.58.974908\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "execution_mode: SYNC\n",
      "deployment_config {\n",
      "  [type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig] {\n",
      "    executor_specs {\n",
      "      key: \"CsvExampleGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec] {\n",
      "          python_executor_spec {\n",
      "            class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    executor_specs {\n",
      "      key: \"SchemaGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec] {\n",
      "          class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    executor_specs {\n",
      "      key: \"StatisticsGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec] {\n",
      "          python_executor_spec {\n",
      "            class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    custom_driver_specs {\n",
      "      key: \"CsvExampleGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec] {\n",
      "          class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    metadata_connection_config {\n",
      "      [type.googleapis.com/ml_metadata.ConnectionConfig] {\n",
      "        sqlite {\n",
      "          filename_uri: \"metadata\\\\penguin-tfdv-schema\\\\metadata.db\"\n",
      "          connection_mode: READWRITE_OPENCREATE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"SchemaGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.schema_gen.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  sqlite {\n",
      "    filename_uri: \"metadata\\\\penguin-tfdv-schema\\\\metadata.db\"\n",
      "    connection_mode: READWRITE_OPENCREATE\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"metadata\\\\penguin-tfdv-schema\\\\metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T14.54.58.974908\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 2\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv-schema\\\\CsvExampleGen\\\\examples\\\\2\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}), exec_properties={'input_base': 'C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898'}, execution_output_uri='pipelines\\\\penguin-tfdv-schema\\\\CsvExampleGen\\\\.system\\\\executor_execution\\\\2\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv-schema\\\\CsvExampleGen\\\\.system\\\\stateful_working_dir\\\\17-06-2021T14.54.58.974908', tmp_dir='pipelines\\\\penguin-tfdv-schema\\\\CsvExampleGen\\\\.system\\\\executor_execution\\\\2\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T14.54.58.974908\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='17-06-2021T14.54.58.974908')\n",
      "INFO:absl:Generating examples.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Processing input csv data C:\\Users\\deaston\\AppData\\Local\\Temp\\tfx-data5untqffl\\* to TFExample.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 2 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv-schema\\\\CsvExampleGen\\\\examples\\\\2\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}) for execution 2\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component StatisticsGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T14.54.58.974908\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T14.54.58.974908\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 3\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'examples': [Artifact(artifact: id: 1\n",
      "type_id: 6\n",
      "uri: \"pipelines\\\\penguin-tfdv-schema\\\\CsvExampleGen\\\\examples\\\\2\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623966900830\n",
      "last_update_time_since_epoch: 1623966900830\n",
      ", artifact_type: id: 6\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv-schema\\\\StatisticsGen\\\\statistics\\\\3\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines\\\\penguin-tfdv-schema\\\\StatisticsGen\\\\.system\\\\executor_execution\\\\3\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv-schema\\\\StatisticsGen\\\\.system\\\\stateful_working_dir\\\\17-06-2021T14.54.58.974908', tmp_dir='pipelines\\\\penguin-tfdv-schema\\\\StatisticsGen\\\\.system\\\\executor_execution\\\\3\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T14.54.58.974908\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T14.54.58.974908\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"SchemaGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='17-06-2021T14.54.58.974908')\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to pipelines\\penguin-tfdv-schema\\StatisticsGen\\statistics\\3\\Split-train.\n",
      "INFO:absl:Generating statistics for split eval.\n",
      "INFO:absl:Statistics for split eval written to pipelines\\penguin-tfdv-schema\\StatisticsGen\\statistics\\3\\Split-eval.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 3 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv-schema\\\\StatisticsGen\\\\statistics\\\\3\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 3\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen is finished.\n",
      "INFO:absl:Component SchemaGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T14.54.58.974908\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T14.54.58.974908\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 4\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={'statistics': [Artifact(artifact: id: 2\n",
      "type_id: 8\n",
      "uri: \"pipelines\\\\penguin-tfdv-schema\\\\StatisticsGen\\\\statistics\\\\3\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623966904158\n",
      "last_update_time_since_epoch: 1623966904158\n",
      ", artifact_type: id: 8\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv-schema\\\\SchemaGen\\\\schema\\\\4\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='pipelines\\\\penguin-tfdv-schema\\\\SchemaGen\\\\.system\\\\executor_execution\\\\4\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv-schema\\\\SchemaGen\\\\.system\\\\stateful_working_dir\\\\17-06-2021T14.54.58.974908', tmp_dir='pipelines\\\\penguin-tfdv-schema\\\\SchemaGen\\\\.system\\\\executor_execution\\\\4\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "  }\n",
      "  id: \"SchemaGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T14.54.58.974908\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv-schema.SchemaGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T14.54.58.974908\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv-schema.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"infer_feature_shape\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv-schema\"\n",
      ", pipeline_run_id='17-06-2021T14.54.58.974908')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-e7a789f6-69ee-4317-94ec-878705ff3a32.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir C:\\Users\\deaston\\Anaconda3\\lib\\site-packages\\tfx to temp dir C:\\Users\\deaston\\AppData\\Local\\Temp\\tmpgdo3ronz\\build\\tfx\n",
      "INFO:absl:Generating a temp setup file at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmpgdo3ronz\\build\\tfx\\setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmpgdo3ronz\\build\\tfx\\setup.log\n",
      "INFO:absl:Added --extra_package=C:\\Users\\deaston\\AppData\\Local\\Temp\\tmpgdo3ronz\\build\\tfx\\dist\\tfx_ephemeral-0.30.0.tar.gz to beam args\n",
      "INFO:absl:Processing schema from statistics for split train.\n",
      "INFO:absl:Processing schema from statistics for split eval.\n",
      "INFO:absl:Schema written to pipelines\\penguin-tfdv-schema\\SchemaGen\\schema\\4\\schema.pbtxt.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 4 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv-schema\\\\SchemaGen\\\\schema\\\\4\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv-schema:17-06-2021T14.54.58.974908:SchemaGen:schema:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}) for execution 4\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component SchemaGen is finished.\n"
     ]
    }
   ],
   "source": [
    "CustomLocalDagRunner().run(\n",
    "  _create_schema_pipeline(\n",
    "      pipeline_name=SCHEMA_PIPELINE_NAME,\n",
    "      pipeline_root=SCHEMA_PIPELINE_ROOT,\n",
    "      data_root=DATA_ROOT,\n",
    "      metadata_path=SCHEMA_METADATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metadata.proto import metadata_store_pb2\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.portable.mlmd import execution_lib\n",
    "\n",
    "# TODO(b/171447278): Move these functions into the TFX library.\n",
    "\n",
    "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
    "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
    "  context = metadata.store.get_context_by_type_and_name(\n",
    "      'node', f'{pipeline_name}.{component_id}')\n",
    "  executions = metadata.store.get_executions_by_context(context.id)\n",
    "  latest_execution = max(executions,\n",
    "                         key=lambda e:e.last_update_time_since_epoch)\n",
    "  return execution_lib.get_artifacts_dict(metadata, latest_execution.id, \n",
    "                                          metadata_store_pb2.Event.OUTPUT)\n",
    "\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.experimental.interactive import visualizations\n",
    "\n",
    "def visualize_artifacts(artifacts):\n",
    "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
    "  for artifact in artifacts:\n",
    "    visualization = visualizations.get_registry().get_visualization(\n",
    "        artifact.type_name)\n",
    "    if visualization:\n",
    "      visualization.display(artifact)\n",
    "\n",
    "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
    "standard_visualizations.register_standard_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    }
   ],
   "source": [
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.metadata import Metadata\n",
    "from tfx.types import standard_component_specs\n",
    "\n",
    "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
    "    SCHEMA_METADATA_PATH)\n",
    "\n",
    "with Metadata(metadata_connection_config) as metadata_handler:\n",
    "  # Find output artifacts from MLMD.\n",
    "  stat_gen_output = get_latest_artifacts(metadata_handler, SCHEMA_PIPELINE_NAME,\n",
    "                                         'StatisticsGen')\n",
    "  stats_artifacts = stat_gen_output[standard_component_specs.STATISTICS_KEY]\n",
    "\n",
    "  schema_gen_output = get_latest_artifacts(metadata_handler,\n",
    "                                           SCHEMA_PIPELINE_NAME, 'SchemaGen')\n",
    "  schema_artifacts = schema_gen_output[standard_component_specs.SCHEMA_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(stats_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'body_mass_g'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'culmen_depth_mm'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'culmen_length_mm'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'flipper_length_mm'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'species'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Type  Presence Valency Domain\n",
       "Feature name                                       \n",
       "'body_mass_g'        FLOAT  required              -\n",
       "'culmen_depth_mm'    FLOAT  required              -\n",
       "'culmen_length_mm'   FLOAT  required              -\n",
       "'flipper_length_mm'  FLOAT  required              -\n",
       "'species'              INT  required              -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(schema_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'schema\\\\schema.pbtxt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "_schema_filename = 'schema.pbtxt'\n",
    "SCHEMA_PATH = 'schema'\n",
    "\n",
    "os.makedirs(SCHEMA_PATH, exist_ok=True)\n",
    "_generated_path = os.path.join(schema_artifacts[0].uri, _schema_filename)\n",
    "\n",
    "# Copy the 'schema.pbtxt' file from the artifact uri to a predefined path.\n",
    "shutil.copy(_generated_path, SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trainer_module_file = 'penguin_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing penguin_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "# We don't need to specify _FEATURE_KEYS and _FEATURE_SPEC any more.\n",
    "# Those information can be read from the given schema file.\n",
    "\n",
    "_LABEL_KEY = 'species'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 20\n",
    "_EVAL_BATCH_SIZE = 10\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int = 200) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    schema: schema of the input data.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _build_keras_model(schema: schema_pb2.Schema) -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "  # The model below is built with Functional API, please refer to\n",
    "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
    "\n",
    "  # ++ Changed code: Uses all features in the schema except the label.\n",
    "  feature_keys = [f.name for f in schema.feature if f.name != _LABEL_KEY]\n",
    "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in feature_keys]\n",
    "  # ++ End of the changed code.\n",
    "\n",
    "  d = keras.layers.concatenate(inputs)\n",
    "  for _ in range(2):\n",
    "    d = keras.layers.Dense(8, activation='relu')(d)\n",
    "  outputs = keras.layers.Dense(3)(d)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(1e-2),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  model.summary(print_fn=logging.info)\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # ++ Changed code: Reads in schema file passed to the Trainer component.\n",
    "  schema = tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema_pb2.Schema())\n",
    "  # ++ End of the changed code.\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _build_keras_model(schema)\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     schema_path: str, module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a pipeline using predefined schema with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Computes statistics over data for visualization and example validation.\n",
    "  statistics_gen = tfx.components.StatisticsGen(\n",
    "      examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # NEW: Import the schema.\n",
    "  schema_importer = tfx.dsl.Importer(\n",
    "      source_uri=schema_path,\n",
    "      artifact_type=tfx.types.standard_artifacts.Schema).with_id('schema_importer')\n",
    "\n",
    "  # NEW: Performs anomaly detection based on statistics and data schema.\n",
    "  example_validator = tfx.components.ExampleValidator(\n",
    "      statistics=statistics_gen.outputs['statistics'],\n",
    "      schema=schema_importer.outputs['result'])\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      schema=schema_importer.outputs['result'],  # Pass the imported schema.\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  components = [\n",
    "      example_gen,\n",
    "\n",
    "      # NEW: Following three components were added to the pipeline.\n",
    "      statistics_gen,\n",
    "      schema_importer,\n",
    "      example_validator,\n",
    "\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Generating ephemeral wheel package for 'C:\\\\Users\\\\deaston\\\\Documents\\\\Python Scripts\\\\TFXPipeline\\\\Tutorial_2\\\\penguin_trainer.py' (including modules: ['penguin_trainer']).\n",
      "INFO:absl:User module package has hash fingerprint version 77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6.\n",
      "INFO:absl:Executing: ['C:\\\\Users\\\\deaston\\\\Anaconda3\\\\python.exe', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tmpn8wqt3kw\\\\_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tmp2wjsk16g', '--dist-dir', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tmp57myjsil']\n",
      "INFO:absl:Successfully built user code wheel distribution at 'pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl'; target user module is 'penguin_trainer'.\n",
      "INFO:absl:Full user module path is 'penguin_trainer@pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl'\n",
      "INFO:absl:Running pipeline:\n",
      " pipeline_info {\n",
      "  id: \"penguin-tfdv\"\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "      }\n",
      "      id: \"CsvExampleGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T15.32.08.801638\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"input_base\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"input_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_data_format\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 6\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.dsl.components.common.importer.Importer\"\n",
      "      }\n",
      "      id: \"schema_importer\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T15.32.08.801638\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv.schema_importer\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"result\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"artifact_uri\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"reimport\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "      }\n",
      "      id: \"StatisticsGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T15.32.08.801638\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv.StatisticsGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T15.32.08.801638\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.trainer.component.Trainer\"\n",
      "      }\n",
      "      id: \"Trainer\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T15.32.08.801638\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv.Trainer\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T15.32.08.801638\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"schema_importer\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T15.32.08.801638\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv.schema_importer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"result\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Model\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"model_run\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ModelRun\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"eval_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"penguin_trainer@pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"train_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    upstream_nodes: \"schema_importer\"\n",
      "    downstream_nodes: \"Pusher\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "      }\n",
      "      id: \"ExampleValidator\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T15.32.08.801638\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv.ExampleValidator\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"schema_importer\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T15.32.08.801638\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv.schema_importer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"result\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T15.32.08.801638\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    upstream_nodes: \"schema_importer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.pusher.component.Pusher\"\n",
      "      }\n",
      "      id: \"Pusher\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"17-06-2021T15.32.08.801638\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"penguin-tfdv.Pusher\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Trainer\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"17-06-2021T15.32.08.801638\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"penguin-tfdv.Trainer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Model\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"model\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"pushed_model\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"PushedModel\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"push_destination\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model\\\\\\\\penguin-tfdv\\\"\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"Trainer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "runtime_spec {\n",
      "  pipeline_root {\n",
      "    field_value {\n",
      "      string_value: \"pipelines\\\\penguin-tfdv\"\n",
      "    }\n",
      "  }\n",
      "  pipeline_run_id {\n",
      "    field_value {\n",
      "      string_value: \"17-06-2021T15.32.08.801638\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "execution_mode: SYNC\n",
      "deployment_config {\n",
      "  [type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig] {\n",
      "    executor_specs {\n",
      "      key: \"CsvExampleGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec] {\n",
      "          python_executor_spec {\n",
      "            class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    executor_specs {\n",
      "      key: \"ExampleValidator\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec] {\n",
      "          class_path: \"tfx.components.example_validator.executor.Executor\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    executor_specs {\n",
      "      key: \"Pusher\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec] {\n",
      "          class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    executor_specs {\n",
      "      key: \"StatisticsGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec] {\n",
      "          python_executor_spec {\n",
      "            class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    executor_specs {\n",
      "      key: \"Trainer\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec] {\n",
      "          class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    custom_driver_specs {\n",
      "      key: \"CsvExampleGen\"\n",
      "      value {\n",
      "        [type.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec] {\n",
      "          class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    metadata_connection_config {\n",
      "      [type.googleapis.com/ml_metadata.ConnectionConfig] {\n",
      "        sqlite {\n",
      "          filename_uri: \"metadata\\\\penguin-tfdv\\\\metadata.db\"\n",
      "          connection_mode: READWRITE_OPENCREATE\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ExampleValidator\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Pusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"Trainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"CsvExampleGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  sqlite {\n",
      "    filename_uri: \"metadata\\\\penguin-tfdv\\\\metadata.db\"\n",
      "    connection_mode: READWRITE_OPENCREATE\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"metadata\\\\penguin-tfdv\\\\metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 6\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=6, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\examples\\\\6\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}), exec_properties={'input_base': 'C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898'}, execution_output_uri='pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\.system\\\\executor_execution\\\\6\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\.system\\\\stateful_working_dir\\\\17-06-2021T15.32.08.801638', tmp_dir='pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\.system\\\\executor_execution\\\\6\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "  }\n",
      "  id: \"CsvExampleGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_base\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tfx-data5untqffl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv\"\n",
      ", pipeline_run_id='17-06-2021T15.32.08.801638')\n",
      "INFO:absl:Generating examples.\n",
      "INFO:absl:Processing input csv data C:\\Users\\deaston\\AppData\\Local\\Temp\\tfx-data5untqffl\\* to TFExample.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 6 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\examples\\\\6\"\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}) for execution 6\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component schema_importer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.importer.Importer\"\n",
      "  }\n",
      "  id: \"schema_importer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.schema_importer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"result\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"artifact_uri\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"reimport\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Running as an importer node.\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Processing source uri: schema, properties: {}, custom_properties: {}\n",
      "INFO:absl:Reusing existing artifact\n",
      "INFO:absl:Component schema_importer is finished.\n",
      "INFO:absl:Component StatisticsGen is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 8\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'examples': [Artifact(artifact: id: 4\n",
      "type_id: 6\n",
      "uri: \"pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\examples\\\\6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623969130201\n",
      "last_update_time_since_epoch: 1623969130201\n",
      ", artifact_type: id: 6\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\StatisticsGen\\\\statistics\\\\8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines\\\\penguin-tfdv\\\\StatisticsGen\\\\.system\\\\executor_execution\\\\8\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv\\\\StatisticsGen\\\\.system\\\\stateful_working_dir\\\\17-06-2021T15.32.08.801638', tmp_dir='pipelines\\\\penguin-tfdv\\\\StatisticsGen\\\\.system\\\\executor_execution\\\\8\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv\"\n",
      ", pipeline_run_id='17-06-2021T15.32.08.801638')\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to pipelines\\penguin-tfdv\\StatisticsGen\\statistics\\8\\Split-train.\n",
      "INFO:absl:Generating statistics for split eval.\n",
      "INFO:absl:Statistics for split eval written to pipelines\\penguin-tfdv\\StatisticsGen\\statistics\\8\\Split-eval.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 8 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\StatisticsGen\\\\statistics\\\\8\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 8\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"schema_importer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.schema_importer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"penguin_trainer@pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"schema_importer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 9\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'examples': [Artifact(artifact: id: 4\n",
      "type_id: 6\n",
      "uri: \"pipelines\\\\penguin-tfdv\\\\CsvExampleGen\\\\examples\\\\6\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"input_fingerprint\"\n",
      "  value {\n",
      "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1623966898,sum_checksum:1623966898\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:CsvExampleGen:examples:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623969130201\n",
      "last_update_time_since_epoch: 1623969130201\n",
      ", artifact_type: id: 6\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      ")], 'schema': [Artifact(artifact: id: 2\n",
      "type_id: 8\n",
      "uri: \"schema\"\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623967833986\n",
      "last_update_time_since_epoch: 1623967833986\n",
      ", artifact_type: id: 8\n",
      "name: \"Schema\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\Trainer\\\\model\\\\9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Model\"\n",
      ")], 'model_run': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\Trainer\\\\model_run\\\\9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'train_args': '{\\n  \"num_steps\": 100\\n}', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'custom_config': 'null', 'module_path': 'penguin_trainer@pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl'}, execution_output_uri='pipelines\\\\penguin-tfdv\\\\Trainer\\\\.system\\\\executor_execution\\\\9\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv\\\\Trainer\\\\.system\\\\stateful_working_dir\\\\17-06-2021T15.32.08.801638', tmp_dir='pipelines\\\\penguin-tfdv\\\\Trainer\\\\.system\\\\executor_execution\\\\9\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"CsvExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.CsvExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"schema_importer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.schema_importer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"penguin_trainer@pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"CsvExampleGen\"\n",
      "upstream_nodes: \"schema_importer\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv\"\n",
      ", pipeline_run_id='17-06-2021T15.32.08.801638')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-e7a789f6-69ee-4317-94ec-878705ff3a32.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir C:\\Users\\deaston\\Anaconda3\\lib\\site-packages\\tfx to temp dir C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp02t2yf5c\\build\\tfx\n",
      "INFO:absl:Generating a temp setup file at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp02t2yf5c\\build\\tfx\\setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp02t2yf5c\\build\\tfx\\setup.log\n",
      "INFO:absl:Added --extra_package=C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp02t2yf5c\\build\\tfx\\dist\\tfx_ephemeral-0.30.0.tar.gz to beam args\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "ERROR:absl:udf_utils.get_fn {'train_args': '{\\n  \"num_steps\": 100\\n}', 'eval_args': '{\\n  \"num_steps\": 5\\n}', 'custom_config': 'null', 'module_path': 'penguin_trainer@pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl'} 'run_fn'\n",
      "INFO:absl:Installing 'pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['C:\\\\Users\\\\deaston\\\\Anaconda3\\\\python.exe', '-m', 'pip', 'install', '--target', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Local\\\\Temp\\\\tmpt_sggs00', 'pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl']\n",
      "INFO:absl:Successfully installed 'pipelines\\\\penguin-tfdv\\\\_wheels\\\\tfx_user_code_Trainer-0.0+77c22302d9caaad6cdedcfdfda4af264e80f8fabb8f74a3d373bfa42d8df6bf6-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature body_mass_g has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature species has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Model: \"model\"\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:body_mass_g (InputLayer)        [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:culmen_depth_mm (InputLayer)    [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:culmen_length_mm (InputLayer)   [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:flipper_length_mm (InputLayer)  [(None, 1)]          0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:concatenate (Concatenate)       (None, 4)            0           body_mass_g[0][0]                \n",
      "INFO:absl:                                                                 culmen_depth_mm[0][0]            \n",
      "INFO:absl:                                                                 culmen_length_mm[0][0]           \n",
      "INFO:absl:                                                                 flipper_length_mm[0][0]          \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense (Dense)                   (None, 8)            40          concatenate[0][0]                \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_1 (Dense)                 (None, 8)            72          dense[0][0]                      \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_2 (Dense)                 (None, 3)            27          dense_1[0][0]                    \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Total params: 139\n",
      "INFO:absl:Trainable params: 139\n",
      "INFO:absl:Non-trainable params: 0\n",
      "INFO:absl:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 1:20 - loss: 1.1266 - sparse_categorical_accuracy: 0.0000e+0 - ETA: 0s - loss: 0.9746 - sparse_categorical_accuracy: 0.2752      - ETA: 0s - loss: 0.8942 - sparse_categorical_accuracy: 0.384 - ETA: 0s - loss: 0.8296 - sparse_categorical_accuracy: 0.468 - ETA: 0s - loss: 0.7708 - sparse_categorical_accuracy: 0.530 - ETA: 0s - loss: 0.7187 - sparse_categorical_accuracy: 0.578 - ETA: 0s - loss: 0.6727 - sparse_categorical_accuracy: 0.617 - ETA: 0s - loss: 0.6355 - sparse_categorical_accuracy: 0.645 - ETA: 0s - loss: 0.6053 - sparse_categorical_accuracy: 0.668 - 2s 7ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.6817 - val_loss: 0.0482 - val_sparse_categorical_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: pipelines\\penguin-tfdv\\Trainer\\model\\9\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipelines\\penguin-tfdv\\Trainer\\model\\9\\Format-Serving\\assets\n",
      "INFO:absl:Training complete. Model written to pipelines\\penguin-tfdv\\Trainer\\model\\9\\Format-Serving. ModelRun written to pipelines\\penguin-tfdv\\Trainer\\model_run\\9\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 9 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\Trainer\\\\model\\\\9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Model\"\n",
      ")], 'model_run': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\Trainer\\\\model_run\\\\9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Trainer:model_run:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}) for execution 9\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component ExampleValidator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"schema_importer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.schema_importer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "upstream_nodes: \"schema_importer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 10\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=10, input_dict={'statistics': [Artifact(artifact: id: 5\n",
      "type_id: 10\n",
      "uri: \"pipelines\\\\penguin-tfdv\\\\StatisticsGen\\\\statistics\\\\8\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:StatisticsGen:statistics:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623969133035\n",
      "last_update_time_since_epoch: 1623969133035\n",
      ", artifact_type: id: 10\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'schema': [Artifact(artifact: id: 2\n",
      "type_id: 8\n",
      "uri: \"schema\"\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623967833986\n",
      "last_update_time_since_epoch: 1623967833986\n",
      ", artifact_type: id: 8\n",
      "name: \"Schema\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\ExampleValidator\\\\anomalies\\\\10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='pipelines\\\\penguin-tfdv\\\\ExampleValidator\\\\.system\\\\executor_execution\\\\10\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv\\\\ExampleValidator\\\\.system\\\\stateful_working_dir\\\\17-06-2021T15.32.08.801638', tmp_dir='pipelines\\\\penguin-tfdv\\\\ExampleValidator\\\\.system\\\\executor_execution\\\\10\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"schema_importer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.schema_importer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "upstream_nodes: \"schema_importer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv\"\n",
      ", pipeline_run_id='17-06-2021T15.32.08.801638')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-e7a789f6-69ee-4317-94ec-878705ff3a32.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir C:\\Users\\deaston\\Anaconda3\\lib\\site-packages\\tfx to temp dir C:\\Users\\deaston\\AppData\\Local\\Temp\\tmppxllqtn5\\build\\tfx\n",
      "INFO:absl:Generating a temp setup file at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmppxllqtn5\\build\\tfx\\setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmppxllqtn5\\build\\tfx\\setup.log\n",
      "INFO:absl:Added --extra_package=C:\\Users\\deaston\\AppData\\Local\\Temp\\tmppxllqtn5\\build\\tfx\\dist\\tfx_ephemeral-0.30.0.tar.gz to beam args\n",
      "INFO:absl:Validating schema against the computed statistics for split train.\n",
      "INFO:absl:Validation complete for split train. Anomalies written to pipelines\\penguin-tfdv\\ExampleValidator\\anomalies\\10\\Split-train.\n",
      "INFO:absl:Validating schema against the computed statistics for split eval.\n",
      "INFO:absl:Validation complete for split eval. Anomalies written to pipelines\\penguin-tfdv\\ExampleValidator\\anomalies\\10\\Split-eval.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 10 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\ExampleValidator\\\\anomalies\\\\10\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:ExampleValidator:anomalies:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 10\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ExampleValidator is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model\\\\\\\\penguin-tfdv\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 11\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=11, input_dict={'model': [Artifact(artifact: id: 6\n",
      "type_id: 12\n",
      "uri: \"pipelines\\\\penguin-tfdv\\\\Trainer\\\\model\\\\9\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Trainer:model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "create_time_since_epoch: 1623969147569\n",
      "last_update_time_since_epoch: 1623969147569\n",
      ", artifact_type: id: 12\n",
      "name: \"Model\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\Pusher\\\\pushed_model\\\\11\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"PushedModel\"\n",
      ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model\\\\\\\\penguin-tfdv\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='pipelines\\\\penguin-tfdv\\\\Pusher\\\\.system\\\\executor_execution\\\\11\\\\executor_output.pb', stateful_working_dir='pipelines\\\\penguin-tfdv\\\\Pusher\\\\.system\\\\stateful_working_dir\\\\17-06-2021T15.32.08.801638', tmp_dir='pipelines\\\\penguin-tfdv\\\\Pusher\\\\.system\\\\executor_execution\\\\11\\\\.temp\\\\', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"17-06-2021T15.32.08.801638\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"penguin-tfdv.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"17-06-2021T15.32.08.801638\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"penguin-tfdv.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model\\\\\\\\penguin-tfdv\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"penguin-tfdv\"\n",
      ", pipeline_run_id='17-06-2021T15.32.08.801638')\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\deaston\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-e7a789f6-69ee-4317-94ec-878705ff3a32.json']\n",
      "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
      "INFO:absl:Copying all content from install dir C:\\Users\\deaston\\Anaconda3\\lib\\site-packages\\tfx to temp dir C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp1h7p3n__\\build\\tfx\n",
      "INFO:absl:Generating a temp setup file at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp1h7p3n__\\build\\tfx\\setup.py\n",
      "INFO:absl:Creating temporary sdist package, logs available at C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp1h7p3n__\\build\\tfx\\setup.log\n",
      "INFO:absl:Added --extra_package=C:\\Users\\deaston\\AppData\\Local\\Temp\\tmp1h7p3n__\\build\\tfx\\dist\\tfx_ephemeral-0.30.0.tar.gz to beam args\n",
      "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n",
      "INFO:absl:Model version: 1623969163\n",
      "INFO:absl:Model written to serving path serving_model\\penguin-tfdv\\1623969163.\n",
      "INFO:absl:Model pushed to pipelines\\penguin-tfdv\\Pusher\\pushed_model\\11.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 11 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines\\\\penguin-tfdv\\\\Pusher\\\\pushed_model\\\\11\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"penguin-tfdv:17-06-2021T15.32.08.801638:Pusher:pushed_model:0\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"0.30.0\"\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"PushedModel\"\n",
      ")]}) for execution 11\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "CustomLocalDagRunner().run(\n",
    "  _create_pipeline(\n",
    "      pipeline_name=PIPELINE_NAME,\n",
    "      pipeline_root=PIPELINE_ROOT,\n",
    "      data_root=DATA_ROOT,\n",
    "      schema_path=SCHEMA_PATH,\n",
    "      module_file=_trainer_module_file,\n",
    "      serving_model_dir=SERVING_MODEL_DIR,\n",
    "      metadata_path=METADATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    }
   ],
   "source": [
    "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
    "    METADATA_PATH)\n",
    "\n",
    "with Metadata(metadata_connection_config) as metadata_handler:\n",
    "  ev_output = get_latest_artifacts(metadata_handler, PIPELINE_NAME,\n",
    "                                   'ExampleValidator')\n",
    "  anomalies_artifacts = ev_output[standard_component_specs.ANOMALIES_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deaston\\Anaconda3\\lib\\site-packages\\tensorflow_data_validation\\utils\\display_util.py:217: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(anomalies_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
